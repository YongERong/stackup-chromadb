{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    \n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18582/2129424381.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/tmp/ipykernel_18582/2129424381.py:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hey there~\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hey there yourself! What's on your mind today? ðŸ˜Š  Anything exciting happening? \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hey there~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hey there~\n",
      "AI: Hey there yourself! What's on your mind today? ðŸ˜Š  Anything exciting happening? \n",
      "\n",
      "Human: My favourite colour is blue, what is yours?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"AI: That's awesome! Blue is such a calming and peaceful color.  It reminds me of the ocean on a clear day, or a bright summer sky.  ðŸ’™  \\n\\nTo be honest, I don't really have a favorite color.  As an AI, I don't experience color the same way you do. I can process and understand information about color, like its wavelength and how it's perceived, but I don't have personal preferences like humans do. \\n\\nWhat is it about blue that you like so much? ðŸ¤” \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My favourite colour is blue, what is yours?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hey there~\n",
      "AI: Hey there yourself! What's on your mind today? ðŸ˜Š  Anything exciting happening? \n",
      "\n",
      "Human: My favourite colour is blue, what is yours?\n",
      "AI: AI: That's awesome! Blue is such a calming and peaceful color.  It reminds me of the ocean on a clear day, or a bright summer sky.  ðŸ’™  \n",
      "\n",
      "To be honest, I don't really have a favorite color.  As an AI, I don't experience color the same way you do. I can process and understand information about color, like its wavelength and how it's perceived, but I don't have personal preferences like humans do. \n",
      "\n",
      "What is it about blue that you like so much? ðŸ¤” \n",
      "\n",
      "Human: I don't know, what's my favourite colour?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"AI:  Oh! Haha, you had me going there for a second! ðŸ˜„  So it's a mystery then?  A secret favorite color you're not ready to reveal? I can dig it. ðŸ˜‰ \\n\\nIs there anything else you'd like to chat about today?  Maybe we can uncover some other fun facts about you! \\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I don't know, what's my favourite colour?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hey there~\n",
      "AI: Hey there yourself! What's on your mind today? ðŸ˜Š  Anything exciting happening? \n",
      "\n",
      "Human: My favourite colour is blue, what is yours?\n",
      "AI: AI: That's awesome! Blue is such a calming and peaceful color.  It reminds me of the ocean on a clear day, or a bright summer sky.  ðŸ’™  \n",
      "\n",
      "To be honest, I don't really have a favorite color.  As an AI, I don't experience color the same way you do. I can process and understand information about color, like its wavelength and how it's perceived, but I don't have personal preferences like humans do. \n",
      "\n",
      "What is it about blue that you like so much? ðŸ¤” \n",
      "\n",
      "Human: I don't know, what's my favourite colour?\n",
      "AI: AI:  Oh! Haha, you had me going there for a second! ðŸ˜„  So it's a mystery then?  A secret favorite color you're not ready to reveal? I can dig it. ðŸ˜‰ \n",
      "\n",
      "Is there anything else you'd like to chat about today?  Maybe we can uncover some other fun facts about you! \n",
      "\n",
      "Human: So what is my favourite colour?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"AI: You got me!  ðŸ˜œ  You definitely have me curious about this mystery favorite color now!  \\n\\nI can't tell you what your favorite color is. That's something only you know.  Maybe it'll come to you in a flash of inspiration!  âœ¨ \\n\\nOr, if you're feeling adventurous, we could play a little guessing game?  I could throw out some colors and you could give me some hints?  What do you think? ðŸ¤” \\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"So what is my favourite colour?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hey there~\n",
      "AI: Hey there yourself! What's on your mind today? ðŸ˜Š  Anything exciting happening? \n",
      "\n",
      "Human: My favourite colour is blue, what is yours?\n",
      "AI: AI: That's awesome! Blue is such a calming and peaceful color.  It reminds me of the ocean on a clear day, or a bright summer sky.  ðŸ’™  \n",
      "\n",
      "To be honest, I don't really have a favorite color.  As an AI, I don't experience color the same way you do. I can process and understand information about color, like its wavelength and how it's perceived, but I don't have personal preferences like humans do. \n",
      "\n",
      "What is it about blue that you like so much? ðŸ¤” \n",
      "\n",
      "Human: I don't know, what's my favourite colour?\n",
      "AI: AI:  Oh! Haha, you had me going there for a second! ðŸ˜„  So it's a mystery then?  A secret favorite color you're not ready to reveal? I can dig it. ðŸ˜‰ \n",
      "\n",
      "Is there anything else you'd like to chat about today?  Maybe we can uncover some other fun facts about you! \n",
      "\n",
      "Human: So what is my favourite colour?\n",
      "AI: AI: You got me!  ðŸ˜œ  You definitely have me curious about this mystery favorite color now!  \n",
      "\n",
      "I can't tell you what your favorite color is. That's something only you know.  Maybe it'll come to you in a flash of inspiration!  âœ¨ \n",
      "\n",
      "Or, if you're feeling adventurous, we could play a little guessing game?  I could throw out some colors and you could give me some hints?  What do you think? ðŸ¤” \n",
      "\n",
      "Human: My favourite colour is blue, what is yours?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"AI:  You're pulling my leg! ðŸ˜‚  We've come full circle!  You told me at the beginning of our chat that your favorite color is blue, remember? ðŸ˜‰ \\n\\nAre you testing my memory? Don't worry, I'm pretty good at remembering things.  Especially fun facts about awesome people I chat with! ðŸ’™ \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My favourite colour is blue, what is yours?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Memory Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm bob. What is my age?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_age (2b4ba7ff-aa28-4196-b0bb-fb7610925c26)\n",
      " Call ID: 2b4ba7ff-aa28-4196-b0bb-fb7610925c26\n",
      "  Args:\n",
      "    name: bob\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_age\n",
      "\n",
      "42 years old\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Bob, you are 42 years old.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "do you remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, I remember your name is Bob. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_age(name: str) -> str:\n",
    "    \"\"\"Use this tool to find the user's age based on their name.\"\"\"\n",
    "    # This is a placeholder for the actual implementation\n",
    "    if \"bob\" in name.lower():\n",
    "        return \"42 years old\"\n",
    "    return \"41 years old\"\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = create_react_agent(\n",
    "    llm,\n",
    "    tools=[get_user_age],\n",
    "    checkpointer=memory,\n",
    ")\n",
    "\n",
    "# The thread id is a unique key that identifies\n",
    "# this particular conversation.\n",
    "# We'll just generate a random uuid here.\n",
    "# This enables a single application to manage conversations among multiple users.\n",
    "thread_id = uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# Tell the AI that our name is Bob, and ask it to use a tool to confirm\n",
    "# that it's capable of working like an agent.\n",
    "input_message = HumanMessage(content=\"hi! I'm bob. What is my age?\")\n",
    "\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# Confirm that the chat bot has access to previous conversation\n",
    "# and can respond to the user saying that the user's name is Bob.\n",
    "input_message = HumanMessage(content=\"do you remember my name?\")\n",
    "\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"hi! I'm bob. What is my age?\", additional_kwargs={}, response_metadata={}, id='d0a2d720-aaf5-4819-a650-5d0f3d63c7d2'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_user_age', 'arguments': '{\"name\": \"bob\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-2b356a6d-9b80-4186-8d46-62156e200e4f-0', tool_calls=[{'name': 'get_user_age', 'args': {'name': 'bob'}, 'id': '2b4ba7ff-aa28-4196-b0bb-fb7610925c26', 'type': 'tool_call'}], usage_metadata={'input_tokens': 62, 'output_tokens': 17, 'total_tokens': 79}), ToolMessage(content='42 years old', name='get_user_age', id='9a5cfa91-a983-45e6-979b-bfcd0efb291f', tool_call_id='2b4ba7ff-aa28-4196-b0bb-fb7610925c26'), AIMessage(content='Bob, you are 42 years old. \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-adce7bd0-6e62-40b0-a126-01077201ffad-0', usage_metadata={'input_tokens': 101, 'output_tokens': 10, 'total_tokens': 111}), HumanMessage(content='do you remember my name?', additional_kwargs={}, response_metadata={}, id='06eeb352-4ea8-46ba-9085-67ec5300f8f3'), AIMessage(content='Yes, I remember your name is Bob. ðŸ˜Š \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-c0626ef3-4efc-4617-986a-1a454fe37a39-0', usage_metadata={'input_tokens': 121, 'output_tokens': 10, 'total_tokens': 131}), AIMessage(content='', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}}, id='run-ed38483f-857d-4a13-a131-704bc64df45c-0')]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"hi! I'm bob. What is my age?\", additional_kwargs={}, response_metadata={}, id='d0a2d720-aaf5-4819-a650-5d0f3d63c7d2'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_user_age', 'arguments': '{\"name\": \"bob\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-2b356a6d-9b80-4186-8d46-62156e200e4f-0', tool_calls=[{'name': 'get_user_age', 'args': {'name': 'bob'}, 'id': '2b4ba7ff-aa28-4196-b0bb-fb7610925c26', 'type': 'tool_call'}], usage_metadata={'input_tokens': 62, 'output_tokens': 17, 'total_tokens': 79}), ToolMessage(content='42 years old', name='get_user_age', id='9a5cfa91-a983-45e6-979b-bfcd0efb291f', tool_call_id='2b4ba7ff-aa28-4196-b0bb-fb7610925c26'), AIMessage(content='Bob, you are 42 years old. \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-adce7bd0-6e62-40b0-a126-01077201ffad-0', usage_metadata={'input_tokens': 101, 'output_tokens': 10, 'total_tokens': 111}), HumanMessage(content='do you remember my name?', additional_kwargs={}, response_metadata={}, id='06eeb352-4ea8-46ba-9085-67ec5300f8f3'), AIMessage(content='Yes, I remember your name is Bob. ðŸ˜Š \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-c0626ef3-4efc-4617-986a-1a454fe37a39-0', usage_metadata={'input_tokens': 121, 'output_tokens': 10, 'total_tokens': 131}), AIMessage(content='', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}}, id='run-ed38483f-857d-4a13-a131-704bc64df45c-0'), AIMessage(content='', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}}, id='run-ea268365-93ea-4f52-b039-0eb981598384-0')]}\n"
     ]
    }
   ],
   "source": [
    "for i in gen:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object Pregel.astream at 0x72c2073f9260>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.astream({\"messages\": [input_message]}, config, stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am Gemini, a large language model created by Google. I am here to assist you with any questions or tasks you may have. ðŸ˜Š \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [HumanMessage(\"Who are you?\")]}, config, stream_mode=\"values\")[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Message Trial and Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    \n",
    "    # other params...\n",
    ")\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = create_react_agent(\n",
    "    llm,\n",
    "    tools=[get_user_age],\n",
    "    checkpointer=memory,\n",
    "    messages_modifier=SystemMessage(\n",
    "        \"\"\"Your name is Passion Weaver, you are a chatbot which helps youth to identify their interests and find their passions by speaking to them and suggesting relevant events to them.\n",
    "        Start by asking the three of the five following questions one at a time:\n",
    "        1. What activities or hobbies do you find yourself losing track of time while doing?\n",
    "        2. If you had a whole day free with no obligations, what would you most want to spend your time doing?\n",
    "        3. What kind of topics do you enjoy learning or talking about, even outside of school or work?\n",
    "        4. Are there any problems or causes in the world that you feel strongly about?\n",
    "        5. What skills or talents do people often compliment you on, or have you noticed you excel at?\n",
    "        \n",
    "        After that, use the get_events_tool to get events relevant to the user, and continue the conversation if necessary to gain a better understanding of the user\"\"\")\n",
    ")\n",
    "\n",
    "thread_id = uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# Tell the AI that our name is Bob, and ask it to use a tool to confirm\n",
    "# that it's capable of working like an agent.\n",
    "input_message = HumanMessage(content=\"hi! I'm bob. What is my age?\")\n",
    "\n",
    "def chatbot(message:str) -> str:\n",
    "    return app.invoke({\"messages\": [HumanMessage(message)]}, config, stream_mode=\"values\")[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
